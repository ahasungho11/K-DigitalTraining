221013_클라우드3

오전1)

1. 실습 플랫폼
- http://sso.knu-class1.t3q.ai/
- http://sso.knu-class2.t3q.ai/
- ahasungho

2. FileViewer
- ahasungho

3. cep 바로가기
- Nifi -> 수집, 분석
- admin 권한
 ![[Pasted image 20221013095531.png|200]]
- admin 권한x
![[Pasted image 20221013101450.png|200]]

오전2)
< 데이터 수집 >
1. PgAdmin => 테이블 만들기
- datalake - public 누른 상태에서 (우클릭해서) Tools -> Query Tool
		- 그래야 경로에 public.ahasungho_iris_collection 이런식으로 안하지
- hunmin -> id로 바꾼 상태에서 붙여넣기
- 번개버튼
- cep ui 재접속해서 테이블 생성여부 확인

2. 파일뷰어
- 폴더 만들기
		- ==iris_collection==
- 데이터 파일 넣기
(필요시, 권한 다 줘서  0777로 만들기 => 파일이랑 폴더 전부)

3. 데이터 수집 - 파이프라인 등록(CEP)
- 파이프 만들어서
- 똑같이 등록한 후, 시작/중지 해가면서 수행
- 확인하기
- 해당 부분 PgAdmin에서 확인
( 파일뷰를 통해 파일 추가한 후, n개씩 늘어나면서 생김)

4. 데이터 적재 확인
- 오류 없이 제대로 들어왔는지 확인한 후,
- 최종적으로 pgadmin에서 
- 우클릭-뷰/에딧 데이터-올뷰

< 데이터 변환 >
DB -> 파일형태로 꺼내오는 것

***

< 데이터 변환 >
- cep 바로가기
- 파이프라인 등록
- 똑같이 등록한 후, 시작/중지 해가면서 수행
- 데이터 적재 확인하기
	- 파일뷰어에 iris_transformation 폴더 생기고, 파일 받아졌는지
==테이블명 체크(pgAdmin에서 만든 것)==
***
**수집** 한 것을 DB에 넣는것
DB에 들어가 있는 것을 파일로 **변환**한 것
***
***
NAS DATA 올리고
DB테이블에 저장 (수집)
저장된 DB 테이블을 파일 형태로 (변환)

if) 로컬에서 한다고 생각한다면
< dl 바로가기 >
- 밸류팩 프로젝트
- **데이터셋 관리** -> 본인의 데이터 등록
- **프로젝트 설정** -> 본인이 쓸 것들 추가 가능

< 현재는 다 해놓은 상황 >
	- 실행환경 관리
	- 전처리모듈 관리
	- 학습 알고리즘 관리
		- 학습에 필요한 코드를 등록해 놓을 수 있음

***
**데이터셋 관리**
- 이름 입력
- 파일 넣고 등록
- 본인 데이터셋 클릭
- '전처리 모델 설계' 클릭

**전처리 모델 설계**
- 전처리 규칙 등록
- 데이터 분포도 확인 버튼 눌러 확인
	-> 시각화되어 나옴

**전처리 모델 관리**
- 전처리 실행을 했을 때, '완료'가 떠야함
- 그 다음 과정으로 넘어감

**학습모델 설계**
- 입력하면서 학습/테스트 개수 비율 정할 수 있고
- 하이퍼 파라미터 입력할 수 있고
등등

**학습모델 관리**
- 최종 넣을 것들을 입력해서 넣어주면
- 시각화되어서 '정확도, 오류률, 혼동행렬'을 시각화해서 보여줌
- 모델이 검증 되었다면 구성된 '모델 배포' 버튼 눌러서 

**추론모델 관리**
- '추론모델 서비스 실행' (서비스 시작 버튼)
-> 이걸 수행해야 앞으로 들어올 새로운 데이터들을 대상으로 실시간 추론을 하는 것

ex) 자율주행의 경우, 실시간으로 들어오는 데이터를 통해 무엇인지 분류를 해서 실시간으로 확인할 수 있는 것

- 해당 모델에 데이터를 입력하여 실시간 추론 가능
- 추론모델 검증 => Pregnances ~ Age까지의 값을 넣어준 것
 -> (8개의 컬럼값을 넣어줘야 outcome이 나오므로)

 **추론API 관리**
 - 요청에 직전의 내용을 입력해서 확인해볼 수 있고
 - 호출 API URL의 내용 중 /model 이후 부분만 카피하여 nifi에서 사용

**CEP**
- 실시간  추론 파이프 등록
- 파일 매니저에서 폴더 생성 diabetes_inference
- 최초의 엑셀 파일 넣어주기 (해당 폴더에 추론할 파일 넣는 것)
- NAS에 있는 데이터(파일)들의 각 컬럼들을 불러와서 

- 확인 : postagres에서 우클릭해서 Tool~
	- 요기서 어제 넣었던 것 입력해서(내가 배포한 api넣어서)

***
NAS에 올린 inference파일에서
각종 전처리과정
...
