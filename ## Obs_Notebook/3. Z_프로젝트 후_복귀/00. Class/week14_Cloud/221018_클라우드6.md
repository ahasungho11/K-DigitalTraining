***
- [x] numpy
- [x] print(sep='', end='')
- [x] CNN 원리
- [ ] U-net
- [ ] AutoEncoder
- [ ] -> 구현된것 수정하면서  해보는 것
- [x] 제텔카스텐 구매
***
7_3
6_1
0,1,2 파일 참고 -> 적용
- 모델 다른 것 or 하이퍼 파라미터 수정
***
## 1. <span style="color: #ffd33d">ConvNets</span>
- 객체인식 -> 영상 내 객체가 어디에 있는지 잘 찾아냄
- 은하 분류, 표지판 인식, 고래 분류, 항공지도를 통함 건물/길 분류 등
- 이미지 분류나 인식을 넘어서 <span style="color: #ffd33d">이미지 캡셔닝(Image Captioning)</span>에도 쓰임
  (이미지가 주어지면 이미지에 대한 설명을 문장으로 만들어 내는 것)
- Neural Network를 이용해 예술작품도 만들어 낼 수 있음
- <span style="color: #ffd33d">스타일 전이(Style Transfer)</span>라고 원본 이미지를 가지고 특정 화풍으로 다시 그려주는 알고리즘도 존재함
- <span style="color: #ffd33d">ImageNet </span>
	: 스탠포드대학의 컴퓨터비전랩, 페이페이리 교수의 주도로 2010년에 만들어진 대회로 트레이닝셋을 주고 이미지 분류 문제를 얼마나 잘 맞출 수 있는지 겨루는 대회. 대회를 통해 현재 딥러닝 신경망 알고리즘들이 급속도로 발전함
***
## 2. <span style="color: #ffd33d">이상탐지</span>
- 정상적인 data가 비정상적인 data가 많음
- 정상적인 data를 확실하게 학습시켜 비정상적인 data를 찾아내는 것
- 도출된 loss값의 평균과 표준편차를 더하여 Threshold를 도출하는 것이 일반적
	- 왼쪽(정상) ---- Threshold  ---- 오른쪽(비정상)
	- 너무 오른쪽으로 하면 대부분의 값들을 정상으로 인식해버리니까 주의
***
## 3. <span style="color: #ffd33d">CNN</span>
1. 이미지는 (높이, 너비, 채널)이라는 3차원 텐서
```
- [높이] 이미지의 세로 방향 픽셀 수
- [너비]는 이미지의 가로 방향 픽셀 수
- [채널]은 색 성분 (흑백(1), 컬러(3) / 채널(channel) 또는 깊이(depth))
- 각 픽셀은 0부터 255 사이의 값을 가짐
```

```
  위 손글씨 데이터는 흑백 이미지므로 채널 수가 1임을 고려하면 (28 × 28 × 1)의 크기를 가지는 3차원 텐서입니다. 그렇다면 흑백이 아니라 우리가 통상적으로 접하게 되는 컬러 이미지는 어떨까요? 컬러 이미지는 적색(Red), 녹색(Green), 청색(Blue) 채널 수가 3개입니다.
```

2. 합성곱 신경망에서 <span style="color: #ffd33d">가중치</span>는 <span style="color: #ffd33d">커널 행렬의 원소들</span>
 ![[Pasted image 20221018163431.png]]
![[Pasted image 20221018163449.png]]
  ![[Pasted image 20221018163348.png|400x200]]
```
  최종적으로 특성 맵을 얻기 위해서는 동일한 커널로 이미지 전체를 훑으며 합성곱 연산을 진행합니다. 결국 이미지 전체를 훑으면서 사용되는 가중치는 w0, w1, w2, w3 4개 뿐입니다. 그리고 각 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아니라, 커널과 맵핑되는 픽셀만을 입력으로 사용하는 것을 볼 수 있습니다.

  결국 합성곱 신경망은 다층 퍼셉트론을 사용할 때보다 훨씬 적은 수의 가중치를 사용하며 공간적 구조 정보를 보존한다는 특징이 있습니다.
```

3. 
- MLP -> 은닉층(가중치 연산) -> 활성화 함수 통과 (for 비선형성 추가)
- CNN -> 특성맵 -> 활성화 함수 통과 (for 비선형성 추가)
	=> 활성화 함수는 ==주로 렐루 함수나 렐루 함수의 변형들==
	
- 합성곱 층(convolution layer)
	: CNN에서, 합성곱 연산을 통해서 특성 맵을 얻고, ==활성화 함수를 지나는 연산을 하는 합성곱 신경망의 층==
- 합성곱 신경망의 편향(bias)
	커널을 적용한 뒤에 편향이 더해짐 (하나의 값만 존재하며, 커널이 적용된 결과의 모든 원소에 더해짐)

- 특성 맵의 크기 계산 방법
	입력의 크기와 커널의 크기, 스트라이드의 값만 알면, 합성곱 연산의 결과인 특성 맵의 크기를 계산 가능
	
	i) 특성 맵의 높이와 너비
	ii) 패딩의 폭을 P라고 하고, 패딩까지 고려한 식

- 다수의 채널을 가질 경우의 합성곱 연산(3차원 텐서의 합성곱 연산) => 컬러일 때
	다수의 채널을 가진 입력 데이터를 가지고 합성곱 연산을 한다고 하면 ==커널의 채널 수도 입력의 채널 수만큼 존재해야== 합니다. 	다시 말해 ==입력 데이터의 채널 수와 커널의 채널 수는 같아야 합니다.== 
	
	채널 수가 같으므로 합성곱 연산을 채널마다 수행합니다. 그리고 **그 결과를 모두 더하여** 최종 특성 맵을 얻습니다.
![[Pasted image 20221018165032.png]]
	-  위 그림은 높이 3, 너비 3, 채널 3의 입력이 높이 2, 너비 2, 채널 3의 커널과 합성곱 연산을 하여 높이 2, 너비 2, 채널 1의 특성 맵을 얻는다는 의미입니다.
	- <span style="color: #ffd33d">합성곱 연산의 결과로 얻은 '특성 맵의 채널 차원'은 RGB 채널 등과 같은 컬러의 의미를 담고 있지는 않습니다.</span>

4. 하나의 입력에 여러 개의 커널을 사용하는 합성곱 연산을 할 수도 있음
	- _다수의 커널_을 사용할 경우, 사용한 커널 수는 합성곱 연산의 결과로 나오는 ==특성 맵의 채널 수==가 됨

5. 풀링(Pooling)
![[Pasted image 20221018170632.png]]
```
- 합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적.
- 풀링층에서는 특성 맵을 다운샘플링하여 특성 맵의 크기를 줄이는 풀링 연산이 이루어짐.
- 최대 풀링(max pooling)과 평균 풀링(average pooling)이 사용.
- 맥스 풀링 : 커널과 겹치는 영역 안에서 최대값을 추출하는 방식으로 다운샘플링
- 평균 풀링 : 평균값을 추출하는 방식으로 다운샘플링
- 커널과 스트라이드 개념이 존재한다는 점에서 합성곱 연산과 유사하지만, 합성곱 연산과의 차이점은 학습해야 할 가중치가 없으며 연산 후에 채널 수가 변하지 않는다는 점
```

***
- [ConV]는 합성곱 연산을 의미
- [합성곱 ]
	: **커널(kernel)** 또는 **필터(filter)** 라는 n×m 크기의 행렬로 높이너비높이(height)×너비(width) 크기의 이미지를 처음부터 끝까지 겹치며 훑으면서 n×m 크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 것
	
- [Convolution Layer(합성곱층)]은 합성곱 연산을 통해서 이미지의 특성을 추출하는 역할을 함
- -> 합성곱 연산의 결과가 활성화 함수 ReLU를 지납니다. 이 두 과정을 <span style="color: #ffd33d">합성곱층(Convolution Layer)</span>이라고 합니다.
- -> 그 후에 <span style="color: #ffd33d">POOL</span>이라는 구간을 지나는데 이는 풀링 연산을 의미하며 <span style="color: #ffd33d">풀링층</span>이라고 함

- 다층 퍼셉트론으로 분류한다고 하면,
	이미지를 1차원 텐서인 벡터로 변환 -> 다층 퍼셉트론의 입력층으로 사용해야 함

```
  1차원으로 변환된 결과는 사람이 보기에도 이게 원래 어떤 이미지였는지 알아보기가 어렵습니다. 이는 기계도 마찬가지 입니다. 위와 같이 결과는 변환 전에 가지고 있던 공간적인 구조(spatial structure) 정보가 유실된 상태입니다.

  여기서 공간적인 구조 정보라는 것은 거리가 가까운 어떤 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리는 값이 비슷하거나 등을 포함하고 있습니다. 결국 '이미지의 공간적인 구조 정보를 보존'하면서 학습할 수 있는 방법이 필요해졌고, 이를 위해 합성곱 신경망(CNN)을 사용
```

- 커널 or 필터는 주로 3x3, 5x5로 진행
	입력 이미지의 그리드 위치와 필터 그리드의 위치가 같은 곳들을 곱해서 더해준 값을 특성맵 칸에 나타내는 것
	
- <span style="color: #ffd33d">특성 맵(feature map)</span> : 합성곱 연산을 통해 나온 결과
- <span style="color: #ffd33d">스트라이드(Stride)</span> : 커널의 이동범위

- <span style="color: #ffd33d">패딩(padding)</span>
	: 합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지시켜줌
- 
- <span style="color: #ffd33d">Convolution Layer(합성곱층)</span>
	: 기본 구조를 보존함==(손실될 수 있는 이미지의 공간적인 구조 정보의 보존)==
```
입력 값으로 32 x 32 x 3 의 이미지가 있고 이 이미지를 길게 펴서 3072차원의 벡터로 만든다. 그리고 가중치 W (10x3072 행렬)를 벡터와 곱하고 (Wx) activiation을 이 layer의 출력값으로 얻는다. 이 예시의 경우 10개의 출력값을 가진다.
```
 ![[Pasted image 20221018144209.png]]

- Fully Connected Layer
	: 어떤 벡터를 가지고 연산을 하는 것
```
32x32x3의 이미지를 받아서 하나의 긴 벡터로 늘리는게 아니라 기존의 이미지 구조 그대로 유지. 파란색의 작은 필터(5x5x3)가 가중치가 된다. 우리는 이 필터를 가지고 이미지를 슬라이딩하면서 공간적으로 내적을 수행하게 된다.
```
![[Pasted image 20221018144242.png]]

- Conv layer 일반적인 세팅
	몇개의 필터를 쓸건지, 필터 크기는 몇인지, stride는 몇으로 할지 zero-padding은 몇 으로 할지 정해줘야하고, 출력의 사이즈가 어떻게 될지 계산도 해야한다.
	-> <span style="color: #ffd33d">필터 사이즈는 3x3, 5x5, Stride는 보통 1이나 2,  padding은 그 설정에 따라 조금씩 다르게, 필터의 갯수는 32, 64, 128, 512 등 2의 제곱수로 한다.</span>

	사람들은 보통 pooling layer에서는 zero-padding를 사용하지 않는다. Pooling 할때는 padding을 고려하지 않고 그냥 downsample만 하면 된다. 가장 널리 쓰이는 필터사이즈는 2 x 2, 3 x 3 이고 보통 stride는 2로 한다.

***
- 패키지는 다시 주피터노트북을 만들면 base 세팅한 상태로 되어서, 다시 깔아야 함
- hub~ stop my sever ->  잡아 놓은 자원 풀어줘야 함 (지금은 어제 그대로 상태인 듯)

- 로컬로 - 환경1개 만들어서, 버전 세팅
- 아나콘다 네비게이터 > 주피터 랩

- [ ] 로컬로 할 수 있는 0번, 1번 파일을 돌려보는 것만 따로
- [ ] 0번 파일 뜯어 보기 => #2번 참고하면서 
- [ ] 뭘 알아야 하나
- [ ] & 어떤 교육을 하나
- [ ] AutoEncoder도 U-net만큼 나오는지 비교해볼 것
- [ ] 성능 개선된 모델을 넣을 수 있다면 넣어볼 것

~~ 패키지 만들어서 이미지로 도커 위에 올리는 것
~~ 그다음 부터 4번 파일부터~

- 패키지 의존성 문제 발생하지 않도록, 환경 갖출 때 패키지 설치 순서도 실험해 가면서 리스트로 만들어 놓는 방법도 알 것
- 기본적인 순서 세팅은 갖춰놓는다는 것
