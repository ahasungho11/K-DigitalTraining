1. 개념도(1)

![[Pasted image 20221021210739.png]]
- HDFS - 원천 데이터 <span style="color: #ffd33d">분산 저장</span>
- MapReduce/YARN - 데이터를 (Key,Value)으로 <span style="color: #ffd33d">분산 처리</span>
- HBase - DB형태로 <span style="color: #ffd33d">저장</span>
- Pig / Hive / Mahout / Oozie - HBase의 데이터들을 <span style="color: #ffd33d">분석</span>해주는 툴
- HUE - 하둡에 접속하는 툴, <span style="color: #ffd33d">화면(인터페이스)
</span>

2. 하둡 기능 보완 S.W(2)

![[Pasted image 20221022035524.png]]
- Hbase (일종의 DBMS) - 저장
- MapReduce (Key, Value)으로 올려보내
- HDFS (데이터가 분산 저장 됨)   -   데이터를 근본적/원초적으로 저장

3. 하둡 프로세스

![[Pasted image 20221022040747.png]]

4. 배포본의 필요성
- 에코시스템을 구성하는 것들은 개별적인 프로그램
- 개별 프로그램들의 버전의 업그레이드는 독자적으로 이뤄짐
	-> 이에 따라 호환이 안되는 경우도 발생
- 이런 경우를 예방하기 위해, 특정 주기를 두고 업그레이드 시켜 호환성에 문제가 없도록 배포판을 만드는 것이다.

5. Pig와 Hive
- 맵리듀스를 통해서 데이터가 처리되어야 분석을 할 수 있음
- 맵리듀스의 분석 및 처리는 JAVA 코딩을 해야함 -> diff -> 자동으로 코딩을 해주는  상위버전의 툴을 만든 것이 -> Pig와 Hive (자동으로 JAVA 코딩 처리)

- Pig : MapReduce 프로그램을 만들어주는 <span style="color: #ffd33d">고수준 언어</span> (Yahoo)
- Hive : <span style="color: #ffd33d">SQL</span>(유사) 구문에서 MapReduce를 자동생성 (Facebook)

****초창기 때에는 HDFS와 MapReduce를 전문가들이 코딩했다면,  
배포한을 통해  쓸 수 있는 상위 프로그램들을 통해 어려운 JAVA코딩이 아닌,
쉽게 할 수 있는 방법이 생긴 것

cf) HUE 인터페이스에 HIVE를 실행중인 장면
![[Pasted image 20221022044304.png]]
- 플라밍고(빅데이터 플랫폼)를 깔면 배포판이 깔리는 것
- 좌측 메뉴를 보면, 생태계를 이루는 프로그램들을 쓸 수 있게끔 얹어져 있음
   (Hive, Pig, R 등)

#### 하둡 - 프레임워크, 분산 저장, 분산 처리
