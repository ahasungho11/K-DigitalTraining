{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. VGGNet 이란?\n",
    "2014년 세계 이미지 분류 대회(ImageNet Large Scale Visual Recognition Challenge)에서 준우승한 CNN 모델이다. \n",
    "간단한 구조로 좋은 성능을 내는 모델로 많이 응용되어 쓰이고 있다.\n",
    "\n",
    "2. VGGNet 구성\n",
    "총 6가지 구성의 VGGNet 모델이 있다. 그중 VGG16(D)과 VGG19(E)를 주로 사용한다.\n",
    "VGGNet 모델에서는 3x3 필터를 사용하여 연산시 발생하는 파라미터의 개수가 줄어드는 효과를 볼 수 있다.\n",
    "이로 인해 속도가 빨라지고 ReLU 함수가 들어갈 수 있는 곳이 많아진다는 장점이 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a79d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. VGG16 Architecture\n",
    "\n",
    "Image(\"파일경로/파일명.확장자명\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe04df6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "model = VGG16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02dca6a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m img_to_array\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvgg16\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_input, decode_predictions\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.preprocessing'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e34d1eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_to_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFM.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 이미지 전처리(자료형 변경)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimg_to_array\u001b[49m(image)\n\u001b[0;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 모델에 넣어준다.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_to_array' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# VGG16 모델 \n",
    "model = VGG16()\n",
    "\n",
    "# 이미지 불러오기 \n",
    "image = cv2.imread(\"FM.jpg\")\n",
    "\n",
    "# 이미지 전처리(자료형 변경)\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0],image.shape[1],image.shape[2]))\n",
    "\n",
    "# 모델에 넣어준다.\n",
    "image = preprocess_input(image)  \n",
    "print(image.shape)\n",
    "\n",
    "# 예측(predict)\n",
    "res = model.predict(image)\n",
    "# 디코딩\n",
    "label = decode_predictions(res)\n",
    "print(label)\n",
    "label = label[0][0]\n",
    "\n",
    "# 출력\n",
    "print()\n",
    "print(\"%s (%.2f%%)\" % (label[1], label[2]*100))\n",
    "print()\n",
    "\n",
    "for i in label:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927c95d",
   "metadata": {},
   "source": [
    "이미지 크기는 224 X 224로 따로 resize 전처리를 해주지 않았다.\n",
    "만약 224 X 224크기가 아니라면 resize 전처리가 필요하다.\n",
    "VGG16 모델 사용 결과 개 사진을 넣었는데 개의 종류인 포메라니안을 예측하는 것을 볼 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
