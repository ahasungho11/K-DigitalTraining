{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa034234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 220905)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐글이나 데이콘에 있는 데이터 활용\n",
    "# 데이터 10000개 정도, 팀 각각, 모델은 다르게\n",
    "# 일반 사회 부분, 팀당 1-2개 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e58580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지난 과제\n",
    "# 이미지 예측\n",
    "# 다중 - 로지스틱회귀, svc\n",
    "# (스케일링 전/후로 차이)\n",
    "\n",
    "# 분류 or 회귀 => 각 해당하는 모델들을 전부 선택해서 가장 나은 것을 선택해야\n",
    "# - 데이터셋마다, 선택하는 피처마다 달라지기 때문에, 무엇이 더 좋은 모델인지\n",
    "# - 정하지는 않는다\n",
    "\n",
    "# SGD => 모델x, 최적화 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc94b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 - 검증 - 테스트 데이터\n",
    "# 학습:테스트 = 8:2\n",
    "# 학습-> 8:2로 또 나누면 여기의 2가 검증 데이터가 되는 것\n",
    "# - 데이터가 적어서 저렇게까지 나누면 과대적합이 나올 수도\n",
    "# - 특성 공학 -> 안된다 싶으면 -> 규제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea444e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 튜닝할 때, 하이퍼파라미터를 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정 트리 (#44~)\n",
    "- 분류/회귀 다 쓰임\n",
    "- 특성 기준을 잡는 것이 가장 중요한 시작\n",
    "- 스케일링 불필요 (YES or NO이기 때문에)\n",
    "- 질문에 따라서 깊이가 달라지고, 빠르게 연산이 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9815d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 -> 큰가/작은가\n",
    "# ex) 50범위에서 맞춰볼게 -> 15보다 크니?\n",
    "\n",
    "# 범주형 -> 속성/피처/특성에 따라 타겟이 결정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3866e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫질문 무엇, 그에 따른 분류, 그다음 질문들 어떻게 \n",
    "# 최대한 데이터가 잘 분리될 수 있도록 하는 속성 선택이 중요함\n",
    "# - 거기에 따라 서브 트리 형성\n",
    "\n",
    "# 동일한 문제지만, 분할 속성에 따라서 깊게/얕게 들어가는 깊이가 달라질 수 있음\n",
    "# -[ 분할 속성 ] 을 무엇으로 할 것이가가 중요\n",
    "# - 가능한 많은 동일 분류의 데이터가 모이는 속성을 선택해야\n",
    "# - [ 불순도 ]와  [ 정보이득 ]\n",
    "# - 불순도의 차이를 보고 정보이득이라고 함\n",
    "\n",
    "# 질문이 좋다면 불순도는 작아지고, 정보이득은 높아져야 함\n",
    "# - ex) 빨강/파랑공 구분\n",
    "# - 따라서, 불순도가 더 낮아지는 것으로 선택해야 좋지\n",
    "# - 불순도의 차이가 점점 커지면서 작아질 것임 (정보이득은 반대겠지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea369d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ 엔트로피 ] : 불순도를 수치화 해놓은 것\n",
    "# 엔트로피가 0이라는 것은 섞여잇는 것이 없고 잘 분류되어 1가지만 있는 것\n",
    "# 엔트로피가 1이라면 다 섞여있어서 골치아픈 상태\n",
    "\n",
    "# ex) # 56~\n",
    "# 1) 패턴 - 대각선/수평/수직\n",
    "# 2) 윤곽 - 점선/실선\n",
    "# 3) 점 - 도형안의 점 유/무\n",
    "# => 가장 불순도가 낮은 기준으로 선택해서 적용\n",
    "\n",
    "# 이후, 한가지 기준으로 분류되는 것 있으면  그것 날리고\n",
    "# - 남은 서브트리에 다시 3가지 적용으로 반복 시행\n",
    "\n",
    "# => 결국, 피처가 많아지면 계산할 것이 많아지는 것\n",
    "\n",
    "# 어떤 결정 기준을 둘 것인가\n",
    "# 불순도와 정보이득간의 차이 -> 엔트로피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ 지니 계수 ] : 얼마나 균일하게 분포되어 있는가\n",
    "# - 대부분 엔트로피 vs. 지니계수 중 지니계수를 많이 씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39261ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오전2)\n",
    "# 64~ : 글씨 색깔 => 과적합 조절을 위한 파라미터들\n",
    "# min_samples_leaf, max_features도 색깔 넣기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
