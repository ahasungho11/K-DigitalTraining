{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43db10f1",
   "metadata": {},
   "source": [
    "## 220902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터 수집\n",
    "데이터 전처리\n",
    "데이터 가공\n",
    "------------------ 요기까지가 중요\n",
    "지역적 특징, 데이터의 특징 등 여러 가지 \n",
    "-------------------\n",
    "모델(학습-데이터제공)=> model\n",
    "모델튜닝(성능개선, 하이퍼 파라미터) -> 최적의 하이퍼 파라미터값을 골라주는\n",
    "\n",
    "훈련과 테스트 둘다 0.99까지 끌어올려야 함\n",
    "다른 데이터를 넣었을 때도 나와야 함\n",
    "\n",
    "*과소x -> 학습이 덜 된 거지\n",
    "그나마 학습을 더 \n",
    "자료 부족이면 자료를 더\n",
    "\n",
    "* 과대x -> 일반화 어려움\n",
    "이게 골치 아픈 것\n",
    "정규화나 표준화\n",
    "\n",
    "원인\n",
    "1. 스케일링의 문제 - 모든 모델이 필요한 것은 아니지만\n",
    "트리는 불필요 (하나 안하나 같음)\n",
    "선형모델은 곱하기가 들어가니까 더욱 중요\n",
    "너무 많이 학습을 해서\n",
    "가중치에 [규제]를 줄 수 있음\n",
    "ex) 모임 장소와의 거리에 따라 차등해서 지불\n",
    "\n",
    "4. 5000개 자료\n",
    "500개 시험 10회로 나눠서 \n",
    "오차를 통해 -> 모델 파라미터 갱신\n",
    "=> 학습 방식(전체 / 나눠서)에 대한 \n",
    "\n",
    "만든사람이 과대적합 체크\n",
    "max_iter 조절해가면서 epoch와 오차 체크해가면서\n",
    "(어떤 모델이더라) => 최적의 학습회수를 찾아야\n",
    "\n",
    "* 훈련과 테스트 스코어가 비슷하게 나와야\n",
    "1) 테스트 해가면서 하이퍼 파라미터 갱신하다보면 과적합할 수 있어서\n",
    "검증 데이터를 준비해서 모델 파라미터 갱신\n",
    "\n",
    "2) 최종 딱한번 테스트\n",
    "- 테스트는 모델 파라미터 갱신할 때 안쓰고\n",
    "\n",
    "=> 3가지 다 모으기는 힘들고, 있는 것으로 분류\n",
    "(그래서 하는 것이 '교차검증')\n",
    "\n",
    "+ 딥러닝에 가면 교차검증은 못씀 (데이터가 너무 많아서),\n",
    "머신러닝에서는 교차검증을 무조건 써야함\n",
    "\n",
    "--------------------------------------------------\n",
    "특히 선형의 경우 - 표준화나 정규화를 통해 스케일을 만들어 줘야\n",
    "(곱셈이라 영향을 너무 많이 받음)\n",
    "\n",
    "거리재서 학습하는 경우 - \n",
    "\n",
    "사이킷런은 안하고 있지만\n",
    "딥러닝 가면 라벨링 인코딩을 해야\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "최적화 => ppt에서 어디인지 확인해서 학습\n",
    "\n",
    "[ 경사하강법 ]\n",
    "* 러닝레이트 => \n",
    " 너무 크면 - \n",
    " 너무 작으면 - max-iter~ 를 조절해서 키워라. ex)100번하니 최적화가 안됐다. 늘려라\n",
    "\n",
    "실제로는 \n",
    "(ppt에 경사하강법 내용에 있음)\n",
    "epoch(에포크) 데이터를 줬을때 1번 다 학습하는 것\n",
    "배치사이즈\n",
    "=> 모델마다 다름\n",
    "\n",
    "파라미터 보고 설정해야하는 것\n",
    "-------------------------------------------\n",
    "+ 사이킷런 site -> 로지스틱 회귀(LogisticRegression)\n",
    "=> max_iter 검색하면 나오는\n",
    "slover='lbfgs'(최적화하는 방법, 디폴트값)\n",
    "penalty='l2'(규제, 릿지로 디폴트값)\n",
    "==> 과대적합 안되게끔 쓰이는 방법\n",
    "\n",
    "tol = 1번 학습할 때 증가야해야할 개선 임계치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.linear_model.SGDClassifier\n",
    "확률적경사하강법(SGD)\n",
    "\n",
    "로지스틱회귀 중 하나\n",
    "+a:\n",
    "n_iter_no_charge=5\n",
    "-> n번 반복할 때까지 개선이 안되면, 강제 종료 시키는 파라미터\n",
    "\n",
    "# 86\n",
    "ppt 경사하강법 내용)\n",
    "- 배치학습 / 오프라인 학습 => BGD\n",
    " -> 한번에 다 공부하고 -> 모델 파라미터 갱신\n",
    " -> 오래걸리지만 정확도는 높지\n",
    "\n",
    "- 점진적 학습 / 온라인 학습 => SGD\n",
    " -> 나눠서 공부하고 -> 모델 파라미터 \n",
    "    -정확도가 좀 떨어짐\n",
    "    \n",
    "- 미니배치경사하강법(MSGD)\n",
    "케라스에서는 기본\n",
    "정확도 향상, 속도면에서 향상\n",
    "\n",
    "- 현재는 거의 Adam을 많이 쓰는 편\n",
    "\n",
    "** 최적화 기법은 본인이 선택해야 함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------\n",
    "=> SGD 최적화(Optimizer)  ==> ppt 찾기\n",
    "- SGD 모델이 아니고, 확률적 경사하강법이 적용된 모델들\n",
    "- 분류와 회귀 모두에 적용\n",
    "\n",
    "* SGDClassifer\n",
    "- 조절하면서 학습진행하는 클래스라서 파라미터 조절할 것들이 많음\n",
    "\n",
    "* SGDRegressor\n",
    "\n",
    "파라미터들 중 중요한 것들이 뭔지 알아야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "-> 모델 선택하는 과정 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76147c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#77\n",
    "로지스틱회귀\n",
    "multi_class 파라미터 \n",
    "-> auto가 디폴트값 => fit()했을 때, 타겟으로 들어오는 데이터를 보고 알아서 이진분류/다중분류 판단해줌\n",
    "-> 그 후, solver가 동작\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb594d6",
   "metadata": {},
   "source": [
    "+ 결정함수를 / 시그모이드나 소프트맥스를 처리해서 / 보여줌 (=> 다 더하면 1)\n",
    "(proba = sigmoid or softmax)\n",
    "\n",
    "predict는 결과만 보여주는 것\n",
    "\n",
    "------------------------------\n",
    "+) \n",
    "다중분류를 했을 때,\n",
    "y=Wx+b가 3개로 들어가니까\n",
    "가중치값과 절편값이 각각 3개씩 나오는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb359c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
