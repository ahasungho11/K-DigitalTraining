{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ea39fb",
   "metadata": {},
   "source": [
    "# 220931"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c07755",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "\n",
    "* 사이킷런이 지도/비지도를 구분해주지는 않고\n",
    "  분석을 통해 데이터/라벨을 구분해서 [ 있으면 -> 지도 / 없으면 -> 비지도 ]\n",
    "\n",
    "* 지정이 안되어 있으면 찾아야 함\n",
    "- 어느 부분이 타겟이 되는지    \n",
    "\n",
    "1. 지도 -> 데이터(Feature, 특성) + 타겟(라벨, 정답)\n",
    " 1) 분류 : 카테고리(범주, 그룹) 나누기\n",
    " 2) 회귀 : 숫자(수치) 정답\n",
    "\n",
    "2. 비지도 -> 데이터(Feature, 특성)\n",
    " - 결과에 대한 평가x\n",
    " - '데이터의 특성을 찾기 위해' 지도학습 이전, 전처리 작업으로 활용多\n",
    "   (for 데이터의 특성(Feature, 특성, 속성) 찾기)\n",
    "    \n",
    "3. 강화 -> 데이터(Feature, 특성)\n",
    " - like 심리학의 보상/강화이론\n",
    " - 피드백 ex) 게임, 걸음마, 자율주행, '시행착오' 겪으면서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d378413",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 지도학습 -> 데이터(Feature, 특성) + 타겟(라벨, 정답)\n",
    " 1) 분류 : 카테고리(범주, 그룹) 나누기\n",
    " 2) 회귀 : 숫자(수치) 정답\n",
    "\n",
    "* 정해져 있는 것도 있지만, 분류/회귀 다 쓰는 것도 있음\n",
    "* KNN -> 분류/회귀\n",
    " - 거리로 하는 것\n",
    " - K개수 - 성능에 가장 큰 영향을 미치는 이웃의 개수\n",
    " - 다수결 => 분류\n",
    "\n",
    "=======================================================================\n",
    "* Regression -> 개수로 나눠서 평균으로 하는 것 => 회귀\n",
    "=======================================================================\n",
    "* [ 선형회귀 ] => y=ax+b (y=Wx+b) => 딥러닝에도 계속 나옴 (1차 함수)\n",
    "\n",
    "모든 데이터에 딱 맞는 것을 찾아나가는 과정에서 \n",
    "최대한 많은 데이터를 만족할 수 있는 식을 찾아가니\n",
    "선형 형태 데이터 분포 -> 선형 회귀\n",
    "\n",
    "=> 차원이 증가한다(다차원)  y=ax1+bx2+C\n",
    "\n",
    "* 중요한 피처만 뽑아서 차원(차수)을 줄여서 시각적으로 볼 수 있도록 해야함\n",
    "-> 특성을 찾고, 없는 것은 만들고 하는 작업(특성공학)을 해야 함\n",
    "\n",
    "* 데이터가 선형이더라 -> 수학 공식처럼 하나 만들어 놓으면 계속해서 쓸 수 있을 것이다\n",
    "-> 방정식을 찾아라\n",
    "=======================================================================\n",
    "* [ 다항회귀 ] => 곡선 형태 데이터 분포 (최대한 많은 데이터를 만족시키고자 하니)\n",
    "=======================================================================\n",
    "* [ 로지스틱 회귀 ]\n",
    "- S자 형태 데이터 분포\n",
    " -> 많은 데이터 만족하는\n",
    "- 신경망의 기본 (딥러닝)\n",
    "\n",
    "- 아무리 그어도 직선을 만족할 수 없음\n",
    " -> 선형으로 존재하는 y=ax+b에 맞춰서 넣을 수가 없어서 \n",
    "\n",
    "- 결국 분류라고 봐야함 (선형을 바탕으로 깔고 가서 '회귀'라고 씀)\n",
    " => y=ax+B를 받아서 / 0과 1로 변환할 수 있는 1개(ex) 시그모이드 함수) 를 더 구해야함\n",
    "-> y값을 시그모이드 함수에 넣어 버림 -> 0과 1을 구할 수 있음\n",
    "\n",
    "* [ 시그모이드 함수 ]\n",
    " - 범위 : 0~1\n",
    "  -> 0.5보다 크면 양수\n",
    "  -> 0.5보다 작으면 음수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13dbc80",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea202c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 데이터 수집 & 준비\n",
    "\n",
    "2. 데이터 전처리\n",
    " - 데이터 / 타겟 분리\n",
    " - 데이터 표준화 / 정규화 작업\n",
    " - 타겟(라벨)에 대한 인코딩 작업\n",
    "\n",
    "3. 학습을 위한 데이터 준비\n",
    " 1) 데이터셋(3)\n",
    "  - 학습용 : 학습 전용\n",
    "  - 검증용 : 모델 생성 중에 사용\n",
    "  - 테스트용 : 모델 완성 후 사용\n",
    "\n",
    "    '''\n",
    "    정확도, 로스 줄이면서 만들어 나가다 보면 테스트용이 되어버리고, 이게 과대적합이 됨\n",
    "    -> 중간에 검증용으로 계속 확인해야됨 => [ 교차검증 ]\n",
    "    머신러닝은 데이터가 적어서 교차검증을 하지만, 딥러닝은 불가능 데이터가 너무 많아서\n",
    "    딥러닝은 학습용-테스트용으로 분리된 상태일 것임\n",
    "    '''\n",
    "    \n",
    "4. 학습 모델 생성\n",
    "  - 학습 방법 선정 및 모델 객체 생성\n",
    "  - 학습 진행\n",
    "   -> [ 모델 파라미터 ] 최적화 => 학습에 의해 결정되는 파라미터\n",
    "    ex) W 가중치, b 절편\n",
    "   -> 최적의 모델 파라미터를 찾기 위한 방법 => [ 최적화(optimizer) ]\n",
    "    ex) (주로) 경사하강법\n",
    "    \n",
    "    cf) KNN에는 별도의 파라미터가 없고\n",
    "    (학습에 의해 결정되는 것이 아니라, K를 결정해주는 것 => [ 하이퍼 파라미터(Hyper parameter) ]\n",
    "  \n",
    "  - 모델 평가\n",
    "   -> 성능개선 => 하이퍼파라미터 (모델마다 다름) => [ 모델 튜닝 ]\n",
    "   ex) KNN -> K / 학습의 횟수 / 1회 학습의 크기(배치 사이즈) / 규제값\n",
    "   -> 흔히 모델 튜닝을 하게 될 것임 ( 0.00단위로 수정 )\n",
    "   ex) K값이 어떻게 다르냐에 따라서 과대/과소적합이 달라짐\n",
    "\n",
    "   -> 과소적합\n",
    "   -> 과대적합 (많이 직면할 것임)\n",
    "    => 원인  : 너무 많이 학습한 것, 피처가 너무 많은 것\n",
    "    => 해결방안 : 규제 (릿지, 라쏘 규제 모델), 학습 회수를 줄여야\n",
    "    \n",
    "5. 모델 테스트\n",
    " - 학습에 사용되지 않은 데이터\n",
    " - 새로운 데이터로 테스트가 진행되어야 함\n",
    " - 회사 규모에 따라 다르겠지만, 개발에 미참여한 사람들에게 배포하는 경우도"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
